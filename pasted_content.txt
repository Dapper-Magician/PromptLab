PromptLab: A Prompt Engineer Workspace application that acts as a Knowledge Workstation and IDE for Prompt Engineering. At it's foundation it stores prompts and allows them to be organized. But it also has versioning control, local database/local server backup, cloud backup, Git/Github connection, Google Drive/OneDrive connection, Notion/Evernote/Obsidian connection. It has an easy to use, customizable clipboard that can store lines from prompts. It has an Espanso like feature that allows designated custom inputs to automatically transform thus allowing quick shortcuts for faster input, whether single lines, full prompts, icons or emojis (the emoji syntax that Discord uses could be helpful here but ultimately everything should be completely customizable). 
It has a stateful multi-section Command Palette that can allow stored prompts to be selected and sent to a side display connected to the Command Palette (CP) so that the User can continually search for prompts, select them, and then continue to search without having to constantly open the CP to select prompts. This would help with arranging prompts. 
It allows properties/frontmatter/metadata to be stored about each prompt so that information like the author/creator, source (where it was taken from), date of creation (if belonging to the user or known when the non-user author made it), date of when it was entered in the application, date of last modified, etc. It has a dynamic sidebar that can hold prompts - this is intended for particular prompts that the user uses frequently. 
It has a testing workbench which can spawn multiple tabs with a single chat entry field which allows multiple simultaneous streaming conversations with different models (or the same model) for testing, with token counts. There also is a tab that works as a browser that specifically leads to the web platforms of Chatgpt, Claude, Google Gemini (Advanced), Google Ai Studio, Groq, and Llama. 
This may be a bit more difficult to implement but ultimately the point is to see how prompts react side by side. 
In each tab there is a feature that easily allows the conversation to be analyzed by AI with all of its information (system message/custom instructions, user messages, model responses, token count, token average per {num} of responses, turns (every user message/model response pair is a turn), cost) where the AI can structure a report and even have inbuilt function calls that perform operations that can calculate costs (per message, response, turn), calculate context drift and semantic drift, total-conversation operations, ratings for user prompts, ratings for model responses, ratings for the specific model, and if possible, ratings based on historical precedence and cross-model results. 
User messages are also able to be easily scooped via a button/modal attached to each user message or via right click (and/or with highlighting text and right clicking) and then stored in the sidebar prompts or the prompts repository. There is also a test area which is very much like the standard chat tab but affords more features such as allowing the user to mark user messages or ai messages with different attributes (thumbs up, star, thumbs down, amongst many others) which allows for metrics to be gathered. API testing can also be done where the user sets up the system prompt and so forth, selects an amount of times to test, and then the applications runs that many identical API calls, gathers and stores the results, and then runs a NLP scripts and an analytical ai agent over them to create accurate metrics for consistency. This kind of test also allows multi-turn testing where pre-created user messages are established, thus allowing the application to automatically engage with the selected model (and prompt) so that the metrics are not solely based off of the first model response. This allows the user to automatically test how consistent their prompt is over multiple calls and how consistent it is across various models. Another variation of this is a benchmark testing platform which stores multiple preconstructed prompt-flows that automatically collect and analyze model responses with pass/fail parameters. There is also a data area that allows high-level and granular reporting as well as data visualization with various visualization views. There is also an area to store prompt templates which can automatically be selected via the various features such as the shortcut system, prompt sidebar, or command palette and each template can be autofilled in with an AI model API call (and the prompt, model parameters, temperature, and everything else can be fully customized) so that once a prompt template is created, it can be used to infinitely generate new prompts. I guess this could actually be a distinct Prompt Creator section. And this goes without saying but, of course there is the ability to edit and save prompts with an extensive selection of options for text editing. There is also a toggleable button that allows Markdown to be rendered or not (viewing/editing mode, as seen in Obsidian). 
